{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the IMDb movie review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pyprind # show process\n",
    "#import pandas as pd\n",
    "#import os\n",
    "#basepath = 'aclImdb'\n",
    "#labels = {'pos':1,'neg':0}\n",
    "#pbar = pyprind.ProgBar(5000)\n",
    "#df = pd.DataFrame()\n",
    "#for s in ('test','train'):\n",
    "#    for l in ('pos','neg'):\n",
    "#        path = os.path.join(basepath,s,l)\n",
    "#        for file in os.listdir(path):\n",
    "#            with open(os.path.join(path,file),'r',encoding='utf-8') as infile:\n",
    "#                txt = infile.read()\n",
    "#                df = df.append([[txt,labels[l]]],ignore_index=True)\n",
    "#                pbar.update()\n",
    "\n",
    "#df.columns = ['review','sentiment']\n",
    "\n",
    "# randomize index and save it to csv file\n",
    "#import numpy as np\n",
    "#np.random.seed(0)\n",
    "#df=df.reindex(np.random.permutation(df.index))\n",
    "#df.to_csv('movie_data.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This 1931 comedy gets better with every viewin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maybe it's because I'm no fan of the comics (b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This service comedy, for which Peter Marshall ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  This 1931 comedy gets better with every viewin...          1\n",
       "1  Maybe it's because I'm no fan of the comics (b...          0\n",
       "2  This service comedy, for which Peter Marshall ...          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_data.csv',encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n nominated. He's just excellent in this this gem.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'review'][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "         text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    " ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply preprocessor\n",
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wsun3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer_porter_stop(text):\n",
    "    return [w for w in tokenizer_porter(text) if w not in stop]\n",
    "df['review'] = df['review'].apply(tokenizer_porter_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thi, 1931, comedi, get, better, everi, view, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mayb, becaus, fan, comic, comic, qualiti, mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thi, servic, comedi, peter, marshal, joann, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  [thi, 1931, comedi, get, better, everi, view, ...          1\n",
       "1  [mayb, becaus, fan, comic, comic, qualiti, mov...          0\n",
       "2  [thi, servic, comedi, peter, marshal, joann, d...          0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('movie_data_preprocessed.csv',index=False,encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('movie_data_preprocessed.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['thi', '1931', 'comedi', 'get', 'better', 'ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mayb', 'becaus', 'fan', 'comic', 'comic', 'q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['thi', 'servic', 'comedi', 'peter', 'marshal'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['9', '10', '30', 'minut', 'pure', 'holiday', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['thi', 'drummond', 'entri', 'lack', 'continu'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['absolut', 'love', 'thi', 'game', 'death', 'e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['le', 'grand', 'voyag', 'gentl', 'miracl', 'f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['one', 'dark', 'night', 'highli', 'overlook',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['heard', 'good', 'thing', 'thi', 'movi', 'pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['may', 'may', 'consid', 'interest', 'onli', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['found', 'get', 'increasingli', 'angri', 'thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['thi', 'one', 'best', 'movi', 'say', 'lot', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['probabl', 'heard', 'thi', 'phrase', 'come', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['american', 'werewolf', 'london', 'funni', 'p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['wa', 'pretti', 'surpris', 'thi', 'flick', 'e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['low', 'budget', 'film', 'like', 'thi', 'give...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['thi', 'film', 'remind', 'soprano', 'good', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['watch', 'thi', 'movi', 'without', 'big', 'ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['thi', 'movi', 'play', 'like', 'english', 've...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['seen', 'movi', 'year', 'ago', 'disappoint', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['fan', 'old', 'seri', 'must', 'say', 'thi', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['frequent', 'comment', 'utter', 'dirth', 'tru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['mood', 'thi', 'movi', 'pretti', 'good', 'cap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['unlik', 'anyon', 'except', 'ador', 'silent',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['serious', 'read', 'review', 'thi', 'film', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['wow', 'thi', 'movi', 'voic', 'climb', 'gener...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['act', 'even', 'bad', 'sinc', 'come', 'mind',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['part', 'celebr', 'releas', 'casino', 'royal'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['weak', 'tale', 'evil', 'warlock', 'search', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['ye', 'georgio', 'light', 'heart', 'enjoy', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>['anoth', 'well', 'done', 'moral', 'ambigu', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>['6', '10', 'act', 'great', 'good', 'act', '4'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49972</th>\n",
       "      <td>['angel', 'bit', 'american', 'obsess', 'often'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49973</th>\n",
       "      <td>['feel', 'extrem', 'sad', 'peopl', 'review', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49974</th>\n",
       "      <td>['lame', 'clich', 'superhero', 'action', 'movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49975</th>\n",
       "      <td>['thi', 'best', 'movi', 'ever', 'opinion', 'sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>['thi', 'far', 'one', 'bore', 'horribl', 'act'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49977</th>\n",
       "      <td>['must', 'admit', 'first', 'expect', 'anyth', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49978</th>\n",
       "      <td>['may', 'contain', 'spoiler', 'luckless', 'sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49979</th>\n",
       "      <td>['realli', 'disagre', 'guy', 'yardley', 'ree',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49980</th>\n",
       "      <td>['well', 'thought', 'movi', 'wa', 'blah', '1',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>['watch', 'revolt', 'zombi', 'star', 'futur', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49982</th>\n",
       "      <td>['must', 'say', 'someth', 'state', 'nation', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>['read', 'comment', 'least', 'one', 'poster', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>['must', 'rememb', 'gammera', 'movi', 'like', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>['dull', 'act', 'weak', 'script', 'worst', 'sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>['thi', 'movi', 'stupid', 'simpli', 'goe', 'ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>['thi', 'certainli', 'worst', 'movi', 'ever', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>['receiv', 'dvd', 'thi', 'sunday', 'newspap', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>['like', 'previou', 'comment', 'thi', 'film', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>['basic', 'slasher', 'movi', 'premis', '3', 'y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>['oop', 'hire', 'thi', 'becaus', 'thought', 'w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>['numer', 'problem', 'thi', 'film', 'contain',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>['lo', 'debutant', 'stori', 'two', 'orphan', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>['babi', 'face', 'precod', 'melodrama', 'star'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>['pain', 'clear', 'effort', 'thi', 'film', 'wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>['littl', 'man', 'dvd', 'wayan', 'brother', 'f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>['thi', 'one', 'best', 'celebr', 'realiti', 's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>['someon', 'must', 'serious', 'joke', 'made', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>['doe', 'anyon', 'know', 'could', 'get', 'hand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      ['thi', '1931', 'comedi', 'get', 'better', 'ev...          1\n",
       "1      ['mayb', 'becaus', 'fan', 'comic', 'comic', 'q...          0\n",
       "2      ['thi', 'servic', 'comedi', 'peter', 'marshal'...          0\n",
       "3      ['9', '10', '30', 'minut', 'pure', 'holiday', ...          1\n",
       "4      ['thi', 'drummond', 'entri', 'lack', 'continu'...          0\n",
       "5      ['absolut', 'love', 'thi', 'game', 'death', 'e...          1\n",
       "6      ['le', 'grand', 'voyag', 'gentl', 'miracl', 'f...          1\n",
       "7      ['one', 'dark', 'night', 'highli', 'overlook',...          1\n",
       "8      ['heard', 'good', 'thing', 'thi', 'movi', 'pro...          1\n",
       "9      ['may', 'may', 'consid', 'interest', 'onli', '...          1\n",
       "10     ['found', 'get', 'increasingli', 'angri', 'thi...          0\n",
       "11     ['thi', 'one', 'best', 'movi', 'say', 'lot', '...          1\n",
       "12     ['probabl', 'heard', 'thi', 'phrase', 'come', ...          0\n",
       "13     ['american', 'werewolf', 'london', 'funni', 'p...          0\n",
       "14     ['wa', 'pretti', 'surpris', 'thi', 'flick', 'e...          1\n",
       "15     ['low', 'budget', 'film', 'like', 'thi', 'give...          0\n",
       "16     ['thi', 'film', 'remind', 'soprano', 'good', '...          0\n",
       "17     ['watch', 'thi', 'movi', 'without', 'big', 'ex...          1\n",
       "18     ['thi', 'movi', 'play', 'like', 'english', 've...          0\n",
       "19     ['seen', 'movi', 'year', 'ago', 'disappoint', ...          1\n",
       "20     ['fan', 'old', 'seri', 'must', 'say', 'thi', '...          0\n",
       "21     ['frequent', 'comment', 'utter', 'dirth', 'tru...          0\n",
       "22     ['mood', 'thi', 'movi', 'pretti', 'good', 'cap...          0\n",
       "23     ['unlik', 'anyon', 'except', 'ador', 'silent',...          0\n",
       "24     ['serious', 'read', 'review', 'thi', 'film', '...          0\n",
       "25     ['wow', 'thi', 'movi', 'voic', 'climb', 'gener...          1\n",
       "26     ['act', 'even', 'bad', 'sinc', 'come', 'mind',...          0\n",
       "27     ['part', 'celebr', 'releas', 'casino', 'royal'...          1\n",
       "28     ['weak', 'tale', 'evil', 'warlock', 'search', ...          0\n",
       "29     ['ye', 'georgio', 'light', 'heart', 'enjoy', '...          1\n",
       "...                                                  ...        ...\n",
       "49970  ['anoth', 'well', 'done', 'moral', 'ambigu', '...          1\n",
       "49971  ['6', '10', 'act', 'great', 'good', 'act', '4'...          0\n",
       "49972  ['angel', 'bit', 'american', 'obsess', 'often'...          1\n",
       "49973  ['feel', 'extrem', 'sad', 'peopl', 'review', '...          1\n",
       "49974  ['lame', 'clich', 'superhero', 'action', 'movi...          0\n",
       "49975  ['thi', 'best', 'movi', 'ever', 'opinion', 'sa...          1\n",
       "49976  ['thi', 'far', 'one', 'bore', 'horribl', 'act'...          0\n",
       "49977  ['must', 'admit', 'first', 'expect', 'anyth', ...          1\n",
       "49978  ['may', 'contain', 'spoiler', 'luckless', 'sou...          0\n",
       "49979  ['realli', 'disagre', 'guy', 'yardley', 'ree',...          1\n",
       "49980  ['well', 'thought', 'movi', 'wa', 'blah', '1',...          0\n",
       "49981  ['watch', 'revolt', 'zombi', 'star', 'futur', ...          0\n",
       "49982  ['must', 'say', 'someth', 'state', 'nation', '...          0\n",
       "49983  ['read', 'comment', 'least', 'one', 'poster', ...          1\n",
       "49984  ['must', 'rememb', 'gammera', 'movi', 'like', ...          0\n",
       "49985  ['dull', 'act', 'weak', 'script', 'worst', 'sp...          0\n",
       "49986  ['thi', 'movi', 'stupid', 'simpli', 'goe', 'ar...          0\n",
       "49987  ['thi', 'certainli', 'worst', 'movi', 'ever', ...          0\n",
       "49988  ['receiv', 'dvd', 'thi', 'sunday', 'newspap', ...          0\n",
       "49989  ['like', 'previou', 'comment', 'thi', 'film', ...          0\n",
       "49990  ['basic', 'slasher', 'movi', 'premis', '3', 'y...          0\n",
       "49991  ['oop', 'hire', 'thi', 'becaus', 'thought', 'w...          0\n",
       "49992  ['numer', 'problem', 'thi', 'film', 'contain',...          0\n",
       "49993  ['lo', 'debutant', 'stori', 'two', 'orphan', '...          1\n",
       "49994  ['babi', 'face', 'precod', 'melodrama', 'star'...          1\n",
       "49995  ['pain', 'clear', 'effort', 'thi', 'film', 'wa...          0\n",
       "49996  ['littl', 'man', 'dvd', 'wayan', 'brother', 'f...          0\n",
       "49997  ['thi', 'one', 'best', 'celebr', 'realiti', 's...          0\n",
       "49998  ['someon', 'must', 'serious', 'joke', 'made', ...          0\n",
       "49999  ['doe', 'anyon', 'know', 'could', 'get', 'hand...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
