{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A self-implemented SVM classifier with similar APIs as in sklearn.svm.svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get iris data from testing purpose\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('iris.data')\n",
    "df.tail()\n",
    "\n",
    "# extract setosa and versicolor\n",
    "y = df.iloc[0:100,4].values\n",
    "y = np.where(y =='Iris-setosa', -1,1)\n",
    "#y[60]=-y[60] # flip a sample such that its not linear separable\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100,[0,2]].values\n",
    "\n",
    "X_std = np.copy(X)\n",
    "X_std[:,0] = (X[:,0]-X[:,0].mean()) /X[:,0].std()\n",
    "X_std[:,1] = (X[:,1]-X[:,1].mean()) /X[:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X_std\n",
    "\n",
    "def kernal_matrix(X,Y,opt):\n",
    "    \"\"\"Need to add kernel options, currently only support linear kernal\"\"\"\n",
    "    return np.dot(X,Y.T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(z):\n",
    "    \"\"\"Define the dual form loss function \"\"\"\n",
    "    K = kernal_matrix(X,X,'linear')\n",
    "    zz = z*y\n",
    "    return -np.dot(np.ones(z.shape),z)+0.5*np.dot(np.dot(zz.T,K),zz)\n",
    "\n",
    "def jac(z):\n",
    "    \"\"\"The jacobian of loss function\"\"\"\n",
    "    K = kernal_matrix(X,X,'linear')\n",
    "    zz = z*y\n",
    "    return np.ones(z.shape) - np.dot(zz.T,K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {'type':'eq','fun':lambda x: np.dot(x,y),'jac':lambda x: y }\n",
    "opt = {'disp':False}\n",
    "C = 5000\n",
    "x0 = np.random.normal(loc=0.0,scale=0.01,size=len(y))\n",
    "bnds = tuple((0,C) for C in C*np.ones(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "QP_res=optimize.minimize(loss,x0,jac=jac,constraints=cons,method='SLSQP',options=opt,bounds=bnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_all=QP_res.x\n",
    "# pick out the support vectors\n",
    "idx = lambdas_all !=0\n",
    "lambdas_s = lambdas_all[idx]\n",
    "ys = y[idx]\n",
    "Xs = X_std[idx,:] \n",
    "theta_hat = np.dot(lambdas_s*ys,Xs)\n",
    "theta0 = (ys-np.dot(Xs,theta_hat)).sum()/len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "def predict(x,lambdas_s,ys,Xs,theta0):\n",
    "    k = kernal_matrix(x,Xs,'linear')\n",
    "    return np.dot(k,lambdas_s*ys)+theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23400843, -0.28218956, -0.28294258, -0.21458538, -0.10888811,\n",
       "       -0.2922776 , -0.20525036, -0.33112371, -0.22467342, -0.12755814,\n",
       "       -0.23476146, -0.25343149, -0.37855181, -0.07787097, -0.06928898,\n",
       "       -0.14622817, -0.19516232, -0.05061895, -0.18582731, -0.10888811,\n",
       "       -0.18582731, -0.32961766, -0.16715728, -0.20675641, -0.19591535,\n",
       "       -0.19591535, -0.16640425, -0.17573927, -0.25418451, -0.23476146,\n",
       "       -0.12755814, -0.16640425, -0.1174701 , -0.22467342, -0.23325541,\n",
       "       -0.12680512, -0.22467342, -0.34045872, -0.18582731, -0.22392039,\n",
       "       -0.32103567, -0.34045872, -0.19591535, -0.14848725, -0.25343149,\n",
       "       -0.17649229, -0.2922776 , -0.1469812 , -0.21458538,  0.48193121,\n",
       "        0.34672285,  0.48117818,  0.12524028,  0.37548092,  0.21076146,\n",
       "        0.34596982, -0.05664315,  0.39490397,  0.0576361 , -0.01855007,\n",
       "        0.22160253,  0.22235555,  0.30712371,  0.10732328,  0.395657  ,\n",
       "        0.19133841,  0.19284446,  0.30787674,  0.13532832,  0.27761262,\n",
       "        0.24177861,  0.36463985,  0.30712371,  0.32805282,  0.37623394,\n",
       "        0.45242011,  0.45166709,  0.26903063,  0.11741132,  0.10657025,\n",
       "        0.09723524,  0.17417443,  0.32504072,  0.1524923 ,  0.26903063,\n",
       "        0.42366204,  0.31796478,  0.15399835,  0.12524028,  0.16258034,\n",
       "        0.2977887 ,  0.18350944, -0.0372201 ,  0.16333336,  0.18275642,\n",
       "        0.18275642,  0.28920671, -0.04580209,  0.1734214 ,  0.46732501])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_std,lambdas_s,ys,Xs,theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see SVM.py for the final classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
